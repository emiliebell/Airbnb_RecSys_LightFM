{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ec417291",
      "metadata": {
        "id": "ec417291"
      },
      "source": [
        "### Step 1: Environment Setup and Library Imports\n",
        "\n",
        "This cell prepares the notebook for execution in Google Colab. It includes three key actions:\n",
        "\n",
        "1. Mounting Google Drive:  \n",
        "   Enables access to local CSV files (e.g., user reviews and listing metadata) that are stored in your Google Drive.\n",
        "\n",
        "2. Installing Required Packages:  \n",
        "   The `lightfm` package is used to build hybrid recommendation models combining collaborative and content-based filtering.\n",
        "\n",
        "3. Importing Dependencies:  \n",
        "   This includes basic libraries (`numpy`, `pandas`, `os`) as well as specialized libraries from LightFM for model construction and evaluation. The `scipy.sparse` module is used to handle sparse matrix operations efficiently.\n",
        "\n",
        "These steps are necessary to ensure that all subsequent code cells execute correctly and reproducibly in the Colab environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "rsjM7UisfR45",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsjM7UisfR45",
        "outputId": "ef3d8265-efbb-4a6a-e09d-18db4b5419b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b29003a9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b29003a9",
        "outputId": "c47760bf-3da0-448d-e9e0-909007534a35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lightfm in /usr/local/lib/python3.11/dist-packages (1.17)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from lightfm) (2.0.2)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.11/dist-packages (from lightfm) (1.14.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from lightfm) (2.32.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from lightfm) (1.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->lightfm) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->lightfm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->lightfm) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->lightfm) (2025.1.31)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->lightfm) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->lightfm) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install lightfm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "NLDQS7IZgY0n",
      "metadata": {
        "id": "NLDQS7IZgY0n"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from itertools import product\n",
        "from lightfm import LightFM\n",
        "from lightfm.data import Dataset\n",
        "from lightfm.evaluation import precision_at_k, recall_at_k, auc_score\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "# Set paths\n",
        "reviews_path = \"/content/drive/MyDrive/Reviews.csv\"\n",
        "listings_path = \"/content/drive/MyDrive/final_listings.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SQxHSrPoiz6A",
      "metadata": {
        "id": "SQxHSrPoiz6A"
      },
      "source": [
        "### Step 2: Feature Engineering Function\n",
        "\n",
        "This cell defines a feature extraction function generator, `make_feature_fn()`, which constructs interpretable item-level features from the Airbnb listing metadata. The function takes six binary flags as input, each representing whether to include a particular category of features:\n",
        "\n",
        "- `room_type` (e.g., Entire home/apt, Private room)\n",
        "- `property_type` (e.g., Apartment, House)\n",
        "- `loc_cluster` (geographical cluster label assigned to each listing)\n",
        "- `price` (binned into low, mid, high)\n",
        "- `review_scores_rating` (high quality if rating > 90)\n",
        "- `accommodates` (number of guests the listing can host)\n",
        "\n",
        "Each listing is transformed into a tuple of the form `(item_idx, [feature_1, feature_2, ...])`, which can be directly passed into LightFM’s item feature construction method.\n",
        "\n",
        "#### Why this step is important:\n",
        "- It enables hybrid modeling by allowing the recommender system to consider both interaction data and content features.\n",
        "- It supports experimentation with different combinations of features during the grid search.\n",
        "- It provides interpretability to the feature space used for training.\n",
        "\n",
        "This feature engineering step aligns with Section 1 of the final report and demonstrates our group’s contribution in selecting meaningful, domain-informed features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "GWjcZpGQfaka",
      "metadata": {
        "id": "GWjcZpGQfaka"
      },
      "outputs": [],
      "source": [
        "def make_feature_fn(use_room, use_prop, use_loc, use_price, use_rating, use_accom):\n",
        "    def fn(items):\n",
        "        out = []\n",
        "        for _, row in items.iterrows():\n",
        "            f = []\n",
        "            if use_room and pd.notna(row.get('room_type')): f.append(f\"room={row['room_type']}\")\n",
        "            if use_prop and pd.notna(row.get('property_type')): f.append(f\"prop={row['property_type']}\")\n",
        "            if use_loc and pd.notna(row.get('loc_cluster')): f.append(f\"loc={row['loc_cluster']}\")\n",
        "            if use_price:\n",
        "                try:\n",
        "                    p = float(row.get('price', 0))\n",
        "                    if p < 50: f.append(\"price=low\")\n",
        "                    elif p < 100: f.append(\"price=mid\")\n",
        "                    else: f.append(\"price=high\")\n",
        "                except: pass\n",
        "            if use_rating:\n",
        "                try:\n",
        "                    r = float(row.get('review_scores_rating', 0))\n",
        "                    if r > 90: f.append(\"rating=high\")\n",
        "                except: pass\n",
        "            if use_accom:\n",
        "                try:\n",
        "                    a = int(row.get('accommodates', 0))\n",
        "                    f.append(f\"accom={a}\")\n",
        "                except: pass\n",
        "            out.append((row['item_idx'], f))\n",
        "        return out\n",
        "    return fn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EW6QrLg-jAWW",
      "metadata": {
        "id": "EW6QrLg-jAWW"
      },
      "source": [
        "### Step 3: Data Loading and Preprocessing\n",
        "\n",
        "This cell defines the `load_data()` function, which is responsible for loading and preprocessing the user-item interaction data and listing metadata. It performs the following key operations:\n",
        "\n",
        "1. **Read and clean user interaction data**  \n",
        "   - Loads the review dataset (user_id, item_id, review_id, date).\n",
        "   - Converts the `date` column to datetime format for later use in time-based splitting.\n",
        "   - Creates a binary target column `booked`, where a missing review ID is interpreted as 0 and a present review ID as 1.\n",
        "\n",
        "2. **Apply interaction frequency filters**  \n",
        "   - Filters out users and items that do not meet the minimum interaction thresholds defined by `min_user_inter` and `min_item_inter`. This step helps to reduce sparsity and improve learning stability.\n",
        "\n",
        "3. **Map IDs to integer indices**  \n",
        "   - Creates mappings from user and item IDs to integer indices, which are required by LightFM.\n",
        "\n",
        "4. **Load and filter listing metadata**  \n",
        "   - Loads the listing data and filters it to include only those items that remain after preprocessing the interaction data.\n",
        "   - Adds `item_idx` to align the listings with the interaction matrix.\n",
        "\n",
        "#### Why this step is important:\n",
        "- It ensures data quality by filtering out sparse users and items.\n",
        "- It aligns the structure of the data with the input format required by LightFM.\n",
        "- It supports reproducibility and modularity, allowing data preparation to be repeated consistently across different experimental configurations.\n",
        "\n",
        "This function plays a foundational role in the pipeline and directly contributes to the performance of the recommendation model by ensuring a clean and consistent dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "JiCxWR3WfdHp",
      "metadata": {
        "id": "JiCxWR3WfdHp"
      },
      "outputs": [],
      "source": [
        "def load_data(reviews_path, listings_path, min_user_inter, min_item_inter):\n",
        "    df = pd.read_csv(reviews_path)\n",
        "    df.columns = ['item_id', 'review_id', 'date', 'user_id']\n",
        "    df['date'] = pd.to_datetime(df['date'])\n",
        "    df['booked'] = df['review_id'].notna().astype(int)\n",
        "\n",
        "    df = df[df['item_id'].map(df['item_id'].value_counts()) >= min_item_inter]\n",
        "    df = df[df['user_id'].map(df['user_id'].value_counts()) >= min_user_inter]\n",
        "\n",
        "    user2idx = {uid: i for i, uid in enumerate(df['user_id'].unique())}\n",
        "    item2idx = {iid: i for i, iid in enumerate(df['item_id'].unique())}\n",
        "    df['user_idx'] = df['user_id'].map(user2idx)\n",
        "    df['item_idx'] = df['item_id'].map(item2idx)\n",
        "\n",
        "    items = pd.read_csv(listings_path)\n",
        "    items = items[items['listing_id'].isin(df['item_id'])]\n",
        "    items['item_idx'] = items['listing_id'].map(item2idx)\n",
        "\n",
        "    return df, items"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nc1RrHNajFwg",
      "metadata": {
        "id": "nc1RrHNajFwg"
      },
      "source": [
        "### Step 4: Time-Based Data Splitting\n",
        "\n",
        "This cell defines the `time_based_split()` function, which partitions the user-item interaction data into training, validation, and test sets based on temporal order. The splitting is performed per user to simulate a realistic recommendation setting, where models are trained on past interactions and evaluated on future behavior.\n",
        "\n",
        "#### Splitting Strategy:\n",
        "- For each user, interactions are sorted by the `date` column.\n",
        "- The first ~70% of interactions are allocated to the training set.\n",
        "- The next ~10% are assigned to the validation set.\n",
        "- The final ~20% are used as the test set.\n",
        "- Users with fewer than 3 interactions are skipped to ensure sufficient data for all three sets.\n",
        "\n",
        "#### Why this step is important:\n",
        "- It prevents data leakage by ensuring that future interactions are not used to inform the model during training.\n",
        "- It allows early stopping to be evaluated properly using validation data that simulates unseen future behavior.\n",
        "- It reflects a real-world usage scenario where recommendations are made based on a user's historical interactions.\n",
        "\n",
        "This function supports valid model evaluation and directly relates to Section 2 of the final report, which emphasizes model performance under realistic conditions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "bJMod1roffWH",
      "metadata": {
        "id": "bJMod1roffWH"
      },
      "outputs": [],
      "source": [
        "def time_based_split(df, val_ratio=0.1, test_ratio=0.2):\n",
        "    df = df.sort_values(\"date\")\n",
        "    train_rows, val_rows, test_rows = [], [], []\n",
        "\n",
        "    for _, group in df.groupby(\"user_id\"):\n",
        "        group = group.sort_values(\"date\")\n",
        "        n = len(group)\n",
        "        if n < 3: continue\n",
        "        n_test = max(1, int(n * test_ratio))\n",
        "        n_val = max(1, int(n * val_ratio))\n",
        "        n_train = n - n_val - n_test\n",
        "        if n_train < 1: continue\n",
        "        train_rows.append(group.iloc[:n_train])\n",
        "        val_rows.append(group.iloc[n_train:n_train + n_val])\n",
        "        test_rows.append(group.iloc[n_train + n_val:])\n",
        "\n",
        "    return pd.concat(train_rows), pd.concat(val_rows), pd.concat(test_rows)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_3oEU9cFjGta",
      "metadata": {
        "id": "_3oEU9cFjGta"
      },
      "source": [
        "### Step 5: Model Training with Early Stopping\n",
        "\n",
        "This cell defines the `train_lightfm_with_early_stopping()` function, which trains a LightFM recommendation model using partial fitting and early stopping based on validation performance.\n",
        "\n",
        "#### Training Procedure:\n",
        "- The model is trained incrementally using `fit_partial()` for one epoch at a time.\n",
        "- After each epoch, the model is evaluated on the validation set using `precision@10`.\n",
        "- If validation performance improves, the current model is saved.\n",
        "- If no improvement is observed for a predefined number of consecutive epochs (`patience`), training stops early to prevent overfitting.\n",
        "\n",
        "#### Parameters:\n",
        "- `train_matrix`: interaction matrix for training\n",
        "- `val_matrix`: interaction matrix for validation\n",
        "- `item_features`: additional item-level content features\n",
        "- `params`: dictionary containing model hyperparameters (e.g., learning rate, number of components)\n",
        "- `max_epochs`: maximum number of epochs allowed\n",
        "- `patience`: number of epochs to wait before stopping if no improvement\n",
        "\n",
        "#### Why this step is important:\n",
        "- Early stopping improves generalization by avoiding overfitting to the training data.\n",
        "- Training in small increments allows precise monitoring of validation performance.\n",
        "- Saving the best model ensures that subsequent evaluations are based on the most effective configuration.\n",
        "\n",
        "This function reflects our effort to make training both efficient and robust. It directly supports the model selection process discussed in Section 2 of the final report.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "_LBd8P-afg48",
      "metadata": {
        "id": "_LBd8P-afg48"
      },
      "outputs": [],
      "source": [
        "def train_lightfm_with_early_stopping(train_matrix, val_matrix, item_features, params, max_epochs=30, patience=5):\n",
        "    model = LightFM(**params)\n",
        "    best_model = None\n",
        "    best_score = -np.inf\n",
        "    wait = 0\n",
        "\n",
        "    for epoch in range(1, max_epochs + 1):\n",
        "        model.fit_partial(train_matrix, item_features=item_features, epochs=1, num_threads=2)\n",
        "        val_score = precision_at_k(model, val_matrix, item_features=item_features, k=10).mean()\n",
        "        print(f\"Epoch {epoch}: val precision@10 = {val_score:.4f}\")\n",
        "\n",
        "        if val_score > best_score + 1e-4:\n",
        "            best_score = val_score\n",
        "            best_model = LightFM(**params)\n",
        "            best_model.__dict__ = model.__dict__.copy()\n",
        "            wait = 0\n",
        "        else:\n",
        "            wait += 1\n",
        "            if wait >= patience:\n",
        "                print(f\"Early stopping at epoch {epoch}\")\n",
        "                break\n",
        "\n",
        "    return best_model, best_score"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9VwD8WcTjKVA",
      "metadata": {
        "id": "9VwD8WcTjKVA"
      },
      "source": [
        "### Step 6: Evaluation Metrics for Top-K Recommendation\n",
        "\n",
        "This cell defines the `evaluate_topk()` function, which evaluates a trained recommendation model using several widely accepted metrics for top-k recommendation tasks.\n",
        "\n",
        "#### Evaluation Procedure:\n",
        "For each user in the test set:\n",
        "- Predict scores for all items.\n",
        "- Remove items the user has already interacted with in the training set to avoid leakage.\n",
        "- Rank items by predicted score and select the top-k items.\n",
        "- Compare these top-k items to the actual test items to compute evaluation metrics.\n",
        "\n",
        "#### Metrics Computed:\n",
        "- **Hit Rate @k (HR@k)**: Proportion of users for whom at least one of the top-k recommended items was relevant.\n",
        "- **Normalized Discounted Cumulative Gain @k (NDCG@k)**: Measures ranking quality, giving higher weight to items appearing earlier in the list.\n",
        "- **Precision @k**: Fraction of recommended items in the top-k that are relevant.\n",
        "- **Recall @k**: Fraction of relevant items that are recommended in the top-k.\n",
        "- **Mean Average Precision (MAP)**: Mean of the average precision scores across all users.\n",
        "- **Area Under the ROC Curve (AUC)**: Measures the model’s ability to rank positive items above negative ones.\n",
        "\n",
        "#### Why this step is important:\n",
        "- These metrics collectively provide a comprehensive view of recommendation quality from multiple perspectives (ranking, relevance, user coverage).\n",
        "- All metrics are calculated in a user-wise manner and averaged, which reflects real-world recommendation performance.\n",
        "- This evaluation method allows fair comparison of different model configurations, aligning directly with Section 2 (Models and Performance) in the report.\n",
        "\n",
        "The results produced by this function are used to select the best model and to report final performance outcomes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "KmgQiLZHfiga",
      "metadata": {
        "id": "KmgQiLZHfiga"
      },
      "outputs": [],
      "source": [
        "def evaluate_topk(model, train_interactions, test_interactions, item_features, k=10):\n",
        "    train_csr = train_interactions.tocsr()\n",
        "    test_csr = test_interactions.tocsr()\n",
        "    num_users, num_items = test_csr.shape\n",
        "    hit, ndcg, precision, recall, ap = [], [], [], [], []\n",
        "\n",
        "    for user_id in range(num_users):\n",
        "        test_items = test_csr[user_id].indices\n",
        "        if len(test_items) == 0: continue\n",
        "\n",
        "        scores = model.predict(user_id, np.arange(num_items), item_features=item_features)\n",
        "        train_items = train_csr[user_id].indices\n",
        "        scores[train_items] = -np.inf\n",
        "\n",
        "        top_k_items = np.argsort(-scores)[:k]\n",
        "\n",
        "        hit_count = np.isin(top_k_items, test_items).sum()\n",
        "        hit.append(1 if hit_count > 0 else 0)\n",
        "        precision.append(hit_count / k)\n",
        "        recall.append(hit_count / len(test_items))\n",
        "\n",
        "        dcg = sum((1.0 / np.log2(idx + 2)) for idx, item in enumerate(top_k_items) if item in test_items)\n",
        "        idcg = sum((1.0 / np.log2(i + 2)) for i in range(min(len(test_items), k)))\n",
        "        ndcg.append(dcg / idcg if idcg > 0 else 0)\n",
        "\n",
        "        num_hits = 0.0\n",
        "        sum_precisions = 0.0\n",
        "        for idx, item in enumerate(top_k_items):\n",
        "            if item in test_items:\n",
        "                num_hits += 1\n",
        "                sum_precisions += num_hits / (idx + 1)\n",
        "        ap.append(sum_precisions / len(test_items) if len(test_items) > 0 else 0)\n",
        "\n",
        "    auc = auc_score(model, test_interactions, item_features=item_features, num_threads=2).mean()\n",
        "\n",
        "    return {\n",
        "        f'HR@{k}': np.mean(hit),\n",
        "        f'NDCG@{k}': np.mean(ndcg),\n",
        "        f'Precision@{k}': np.mean(precision),\n",
        "        f'Recall@{k}': np.mean(recall),\n",
        "        'MAP': np.mean(ap),\n",
        "        'AUC': auc\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "L4Q90VrDjOkk",
      "metadata": {
        "id": "L4Q90VrDjOkk"
      },
      "source": [
        "### Step 7: Hyperparameter Grid Search and Model Selection\n",
        "\n",
        "This cell defines the `simple_grid_search_and_run()` function, which performs an automated grid search over several LightFM hyperparameters and selects the best model based on validation performance.\n",
        "\n",
        "#### Grid Search Setup:\n",
        "The function searches over all combinations of the following parameters:\n",
        "- `dim`: dimensionality of latent factors (e.g., 16, 32)\n",
        "- `lr`: learning rate (e.g., 0.01, 0.03)\n",
        "- `loss`: loss function (e.g., 'warp', 'bpr')\n",
        "- `alpha`: regularization strength (e.g., 1e-6, 1e-5)\n",
        "\n",
        "Each configuration is evaluated as follows:\n",
        "1. Load data with the specified interaction thresholds.\n",
        "2. Extract item features based on the binary flags in `config['feat']`.\n",
        "3. Filter out datasets with excessive sparsity (`sparsity < 0.001`) to avoid unreliable training.\n",
        "4. Train the model using early stopping based on validation precision@10.\n",
        "5. Track and store the best-performing configuration and corresponding model.\n",
        "\n",
        "#### Why this step is important:\n",
        "- Grid search is essential to find a strong-performing configuration without overfitting.\n",
        "- Skipping sparse configurations improves efficiency and stability.\n",
        "- Selecting the model based on validation performance ensures that the final evaluation is meaningful and generalizable.\n",
        "\n",
        "This function is central to the experimentation process described in Section 2 of the final report. It demonstrates our systematic and data-driven approach to model selection.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "WsI_NUqqfpq5",
      "metadata": {
        "id": "WsI_NUqqfpq5"
      },
      "outputs": [],
      "source": [
        "def simple_grid_search_and_run(config_base, dim_list, lr_list, loss_list, alpha_list):\n",
        "    best_score = -np.inf\n",
        "    best_config = None\n",
        "\n",
        "    for dim, lr, loss, alpha in product(dim_list, lr_list, loss_list, alpha_list):\n",
        "        config = config_base.copy()\n",
        "        config.update({'dim': dim, 'lr': lr, 'loss': loss, 'alpha': alpha})\n",
        "\n",
        "        try:\n",
        "            print(f\"\\nTrying config: {config}\")\n",
        "            feat_flags = list(map(int, list(config['feat'])))\n",
        "            extract_fn = make_feature_fn(*feat_flags)\n",
        "            df, items = load_data(reviews_path, listings_path, config['min_user'], config['min_item'])\n",
        "            feats = extract_fn(items)\n",
        "\n",
        "            dset = Dataset()\n",
        "            dset.fit(df['user_idx'], df['item_idx'], item_features=set(f for _, fl in feats for f in fl))\n",
        "\n",
        "            full_matrix, _ = dset.build_interactions(list(df[['user_idx', 'item_idx', 'booked']].itertuples(index=False, name=None)))\n",
        "            sparsity = full_matrix.nnz / (full_matrix.shape[0] * full_matrix.shape[1])\n",
        "            print(f\"Sparsity: {sparsity:.6f}\")\n",
        "            if sparsity < 0.001:\n",
        "                print(\"Skipping due to high sparsity\")\n",
        "                continue\n",
        "\n",
        "            train_df, val_df, test_df = time_based_split(df)\n",
        "            train_i = list(train_df[['user_idx', 'item_idx', 'booked']].itertuples(index=False, name=None))\n",
        "            val_i = list(val_df[['user_idx', 'item_idx', 'booked']].itertuples(index=False, name=None))\n",
        "            test_i = list(test_df[['user_idx', 'item_idx', 'booked']].itertuples(index=False, name=None))\n",
        "\n",
        "            train, _ = dset.build_interactions(train_i)\n",
        "            val, _ = dset.build_interactions(val_i)\n",
        "            test, _ = dset.build_interactions(test_i)\n",
        "            feat_mat = dset.build_item_features(feats)\n",
        "\n",
        "            params = {\n",
        "                'no_components': config['dim'],\n",
        "                'learning_rate': config['lr'],\n",
        "                'loss': config['loss'],\n",
        "                'item_alpha': config['alpha']\n",
        "            }\n",
        "\n",
        "            model, val_score = train_lightfm_with_early_stopping(train, val, feat_mat, params)\n",
        "            print(f\"Validation Precision@10: {val_score:.4f}\")\n",
        "\n",
        "            if val_score > best_score:\n",
        "                best_score = val_score\n",
        "                best_config = config\n",
        "                best_model = model\n",
        "                best_test = test\n",
        "                best_feat_mat = feat_mat\n",
        "                best_train = train\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Skipped config due to error: {e}\")\n",
        "            continue\n",
        "\n",
        "    print(\"\\n===== BEST CONFIG =====\")\n",
        "    print(best_config)\n",
        "    print(\"========================\\n\")\n",
        "\n",
        "    # Evaluate best model\n",
        "    results = evaluate_topk(best_model, best_train, best_test, item_features=best_feat_mat, k=10)\n",
        "    print(\"Final Evaluation Results:\")\n",
        "    for k, v in results.items():\n",
        "        print(f\"{k}: {v:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-eoAcR6jjRlx",
      "metadata": {
        "id": "-eoAcR6jjRlx"
      },
      "source": [
        "### Step 8: Execute Grid Search and Evaluate the Best Model\n",
        "\n",
        "This final cell defines the baseline configuration and triggers the `simple_grid_search_and_run()` function, which executes the full pipeline:\n",
        "\n",
        "1. Loads data.\n",
        "2. Extracts features.\n",
        "3. Trains and validates models across hyperparameter combinations.\n",
        "4. Selects the best model based on validation precision@10.\n",
        "5. Evaluates the best model on the test set using six different top-k metrics.\n",
        "\n",
        "#### Configuration:\n",
        "```python\n",
        "config_base = {\n",
        "    'feat': '001010',     # Use loc_cluster and review_scores_rating\n",
        "    'min_user': 10,       # Minimum number of interactions per user\n",
        "    'min_item': 20        # Minimum number of interactions per item\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "iZcdai_8fs8f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZcdai_8fs8f",
        "outputId": "abe1f0a0-9e20-4489-849c-5e0e34ab81e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trying config: {'feat': '001010', 'min_user': 10, 'min_item': 20, 'dim': 16, 'lr': 0.01, 'loss': 'warp', 'alpha': 1e-06}\n",
            "Sparsity: 0.001059\n",
            "Epoch 1: val precision@10 = 0.0005\n",
            "Epoch 2: val precision@10 = 0.0010\n",
            "Epoch 3: val precision@10 = 0.0017\n",
            "Epoch 4: val precision@10 = 0.0023\n",
            "Epoch 5: val precision@10 = 0.0032\n",
            "Epoch 6: val precision@10 = 0.0043\n",
            "Epoch 7: val precision@10 = 0.0055\n",
            "Epoch 8: val precision@10 = 0.0057\n",
            "Epoch 9: val precision@10 = 0.0065\n",
            "Epoch 10: val precision@10 = 0.0073\n",
            "Epoch 11: val precision@10 = 0.0082\n",
            "Epoch 12: val precision@10 = 0.0088\n",
            "Epoch 13: val precision@10 = 0.0093\n",
            "Epoch 14: val precision@10 = 0.0096\n",
            "Epoch 15: val precision@10 = 0.0102\n",
            "Epoch 16: val precision@10 = 0.0107\n",
            "Epoch 17: val precision@10 = 0.0111\n",
            "Epoch 18: val precision@10 = 0.0116\n",
            "Epoch 19: val precision@10 = 0.0120\n",
            "Epoch 20: val precision@10 = 0.0122\n",
            "Epoch 21: val precision@10 = 0.0126\n",
            "Epoch 22: val precision@10 = 0.0129\n",
            "Epoch 23: val precision@10 = 0.0133\n",
            "Epoch 24: val precision@10 = 0.0134\n",
            "Epoch 25: val precision@10 = 0.0138\n",
            "Epoch 26: val precision@10 = 0.0141\n",
            "Epoch 27: val precision@10 = 0.0143\n",
            "Epoch 28: val precision@10 = 0.0146\n",
            "Epoch 29: val precision@10 = 0.0147\n",
            "Epoch 30: val precision@10 = 0.0152\n",
            "Validation Precision@10: 0.0152\n",
            "\n",
            "Trying config: {'feat': '001010', 'min_user': 10, 'min_item': 20, 'dim': 16, 'lr': 0.01, 'loss': 'warp', 'alpha': 1e-05}\n",
            "Sparsity: 0.001059\n",
            "Epoch 1: val precision@10 = 0.0006\n",
            "Epoch 2: val precision@10 = 0.0011\n",
            "Epoch 3: val precision@10 = 0.0015\n",
            "Epoch 4: val precision@10 = 0.0026\n",
            "Epoch 5: val precision@10 = 0.0037\n",
            "Epoch 6: val precision@10 = 0.0037\n",
            "Epoch 7: val precision@10 = 0.0045\n",
            "Epoch 8: val precision@10 = 0.0048\n",
            "Epoch 9: val precision@10 = 0.0056\n",
            "Epoch 10: val precision@10 = 0.0060\n",
            "Epoch 11: val precision@10 = 0.0065\n",
            "Epoch 12: val precision@10 = 0.0071\n",
            "Epoch 13: val precision@10 = 0.0078\n",
            "Epoch 14: val precision@10 = 0.0081\n",
            "Epoch 15: val precision@10 = 0.0086\n",
            "Epoch 16: val precision@10 = 0.0088\n",
            "Epoch 17: val precision@10 = 0.0090\n",
            "Epoch 18: val precision@10 = 0.0094\n",
            "Epoch 19: val precision@10 = 0.0099\n",
            "Epoch 20: val precision@10 = 0.0106\n",
            "Epoch 21: val precision@10 = 0.0108\n",
            "Epoch 22: val precision@10 = 0.0113\n",
            "Epoch 23: val precision@10 = 0.0117\n",
            "Epoch 24: val precision@10 = 0.0121\n",
            "Epoch 25: val precision@10 = 0.0125\n",
            "Epoch 26: val precision@10 = 0.0126\n",
            "Epoch 27: val precision@10 = 0.0130\n",
            "Epoch 28: val precision@10 = 0.0131\n",
            "Epoch 29: val precision@10 = 0.0132\n",
            "Epoch 30: val precision@10 = 0.0134\n",
            "Validation Precision@10: 0.0134\n",
            "\n",
            "Trying config: {'feat': '001010', 'min_user': 10, 'min_item': 20, 'dim': 16, 'lr': 0.01, 'loss': 'bpr', 'alpha': 1e-06}\n",
            "Sparsity: 0.001059\n",
            "Epoch 1: val precision@10 = 0.0001\n",
            "Epoch 2: val precision@10 = 0.0001\n",
            "Epoch 3: val precision@10 = 0.0000\n",
            "Epoch 4: val precision@10 = 0.0002\n",
            "Epoch 5: val precision@10 = 0.0004\n",
            "Epoch 6: val precision@10 = 0.0005\n",
            "Epoch 7: val precision@10 = 0.0005\n",
            "Epoch 8: val precision@10 = 0.0005\n",
            "Epoch 9: val precision@10 = 0.0007\n",
            "Epoch 10: val precision@10 = 0.0008\n",
            "Epoch 11: val precision@10 = 0.0008\n",
            "Epoch 12: val precision@10 = 0.0010\n",
            "Epoch 13: val precision@10 = 0.0010\n",
            "Epoch 14: val precision@10 = 0.0011\n",
            "Epoch 15: val precision@10 = 0.0012\n",
            "Epoch 16: val precision@10 = 0.0013\n",
            "Epoch 17: val precision@10 = 0.0013\n",
            "Epoch 18: val precision@10 = 0.0013\n",
            "Epoch 19: val precision@10 = 0.0016\n",
            "Epoch 20: val precision@10 = 0.0019\n",
            "Epoch 21: val precision@10 = 0.0020\n",
            "Epoch 22: val precision@10 = 0.0021\n",
            "Epoch 23: val precision@10 = 0.0023\n",
            "Epoch 24: val precision@10 = 0.0025\n",
            "Epoch 25: val precision@10 = 0.0026\n",
            "Epoch 26: val precision@10 = 0.0026\n",
            "Epoch 27: val precision@10 = 0.0026\n",
            "Epoch 28: val precision@10 = 0.0024\n",
            "Epoch 29: val precision@10 = 0.0024\n",
            "Epoch 30: val precision@10 = 0.0024\n",
            "Early stopping at epoch 30\n",
            "Validation Precision@10: 0.0026\n",
            "\n",
            "Trying config: {'feat': '001010', 'min_user': 10, 'min_item': 20, 'dim': 16, 'lr': 0.01, 'loss': 'bpr', 'alpha': 1e-05}\n",
            "Sparsity: 0.001059\n",
            "Epoch 1: val precision@10 = 0.0001\n",
            "Epoch 2: val precision@10 = 0.0002\n",
            "Epoch 3: val precision@10 = 0.0002\n",
            "Epoch 4: val precision@10 = 0.0004\n",
            "Epoch 5: val precision@10 = 0.0005\n",
            "Epoch 6: val precision@10 = 0.0004\n",
            "Epoch 7: val precision@10 = 0.0005\n",
            "Epoch 8: val precision@10 = 0.0005\n",
            "Epoch 9: val precision@10 = 0.0005\n",
            "Epoch 10: val precision@10 = 0.0007\n",
            "Epoch 11: val precision@10 = 0.0009\n",
            "Epoch 12: val precision@10 = 0.0013\n",
            "Epoch 13: val precision@10 = 0.0014\n",
            "Epoch 14: val precision@10 = 0.0014\n",
            "Epoch 15: val precision@10 = 0.0016\n",
            "Epoch 16: val precision@10 = 0.0017\n",
            "Epoch 17: val precision@10 = 0.0018\n",
            "Epoch 18: val precision@10 = 0.0017\n",
            "Epoch 19: val precision@10 = 0.0021\n",
            "Epoch 20: val precision@10 = 0.0022\n",
            "Epoch 21: val precision@10 = 0.0022\n",
            "Epoch 22: val precision@10 = 0.0022\n",
            "Epoch 23: val precision@10 = 0.0023\n",
            "Epoch 24: val precision@10 = 0.0024\n",
            "Epoch 25: val precision@10 = 0.0024\n",
            "Epoch 26: val precision@10 = 0.0029\n",
            "Epoch 27: val precision@10 = 0.0029\n",
            "Epoch 28: val precision@10 = 0.0030\n",
            "Epoch 29: val precision@10 = 0.0030\n",
            "Epoch 30: val precision@10 = 0.0030\n",
            "Validation Precision@10: 0.0030\n",
            "\n",
            "Trying config: {'feat': '001010', 'min_user': 10, 'min_item': 20, 'dim': 16, 'lr': 0.03, 'loss': 'warp', 'alpha': 1e-06}\n",
            "Sparsity: 0.001059\n",
            "Epoch 1: val precision@10 = 0.0026\n",
            "Epoch 2: val precision@10 = 0.0060\n",
            "Epoch 3: val precision@10 = 0.0094\n",
            "Epoch 4: val precision@10 = 0.0119\n",
            "Epoch 5: val precision@10 = 0.0141\n",
            "Epoch 6: val precision@10 = 0.0160\n",
            "Epoch 7: val precision@10 = 0.0172\n",
            "Epoch 8: val precision@10 = 0.0183\n",
            "Epoch 9: val precision@10 = 0.0191\n",
            "Epoch 10: val precision@10 = 0.0199\n",
            "Epoch 11: val precision@10 = 0.0207\n",
            "Epoch 12: val precision@10 = 0.0213\n",
            "Epoch 13: val precision@10 = 0.0219\n",
            "Epoch 14: val precision@10 = 0.0228\n",
            "Epoch 15: val precision@10 = 0.0233\n",
            "Epoch 16: val precision@10 = 0.0239\n",
            "Epoch 17: val precision@10 = 0.0242\n",
            "Epoch 18: val precision@10 = 0.0249\n",
            "Epoch 19: val precision@10 = 0.0252\n",
            "Epoch 20: val precision@10 = 0.0256\n",
            "Epoch 21: val precision@10 = 0.0261\n",
            "Epoch 22: val precision@10 = 0.0263\n",
            "Epoch 23: val precision@10 = 0.0270\n",
            "Epoch 24: val precision@10 = 0.0273\n",
            "Epoch 25: val precision@10 = 0.0274\n",
            "Epoch 26: val precision@10 = 0.0276\n",
            "Epoch 27: val precision@10 = 0.0280\n",
            "Epoch 28: val precision@10 = 0.0282\n",
            "Epoch 29: val precision@10 = 0.0285\n",
            "Epoch 30: val precision@10 = 0.0285\n",
            "Validation Precision@10: 0.0285\n",
            "\n",
            "Trying config: {'feat': '001010', 'min_user': 10, 'min_item': 20, 'dim': 16, 'lr': 0.03, 'loss': 'warp', 'alpha': 1e-05}\n",
            "Sparsity: 0.001059\n",
            "Epoch 1: val precision@10 = 0.0030\n",
            "Epoch 2: val precision@10 = 0.0053\n",
            "Epoch 3: val precision@10 = 0.0083\n",
            "Epoch 4: val precision@10 = 0.0104\n",
            "Epoch 5: val precision@10 = 0.0126\n",
            "Epoch 6: val precision@10 = 0.0139\n",
            "Epoch 7: val precision@10 = 0.0159\n",
            "Epoch 8: val precision@10 = 0.0166\n",
            "Epoch 9: val precision@10 = 0.0181\n",
            "Epoch 10: val precision@10 = 0.0186\n",
            "Epoch 11: val precision@10 = 0.0191\n",
            "Epoch 12: val precision@10 = 0.0199\n",
            "Epoch 13: val precision@10 = 0.0206\n",
            "Epoch 14: val precision@10 = 0.0213\n",
            "Epoch 15: val precision@10 = 0.0223\n",
            "Epoch 16: val precision@10 = 0.0228\n",
            "Epoch 17: val precision@10 = 0.0231\n",
            "Epoch 18: val precision@10 = 0.0235\n",
            "Epoch 19: val precision@10 = 0.0236\n",
            "Epoch 20: val precision@10 = 0.0242\n",
            "Epoch 21: val precision@10 = 0.0247\n",
            "Epoch 22: val precision@10 = 0.0251\n",
            "Epoch 23: val precision@10 = 0.0255\n",
            "Epoch 24: val precision@10 = 0.0258\n",
            "Epoch 25: val precision@10 = 0.0261\n",
            "Epoch 26: val precision@10 = 0.0263\n",
            "Epoch 27: val precision@10 = 0.0266\n",
            "Epoch 28: val precision@10 = 0.0266\n",
            "Epoch 29: val precision@10 = 0.0272\n",
            "Epoch 30: val precision@10 = 0.0272\n",
            "Validation Precision@10: 0.0272\n",
            "\n",
            "Trying config: {'feat': '001010', 'min_user': 10, 'min_item': 20, 'dim': 16, 'lr': 0.03, 'loss': 'bpr', 'alpha': 1e-06}\n",
            "Sparsity: 0.001059\n",
            "Epoch 1: val precision@10 = 0.0002\n",
            "Epoch 2: val precision@10 = 0.0002\n",
            "Epoch 3: val precision@10 = 0.0005\n",
            "Epoch 4: val precision@10 = 0.0005\n",
            "Epoch 5: val precision@10 = 0.0007\n",
            "Epoch 6: val precision@10 = 0.0009\n",
            "Epoch 7: val precision@10 = 0.0013\n",
            "Epoch 8: val precision@10 = 0.0015\n",
            "Epoch 9: val precision@10 = 0.0020\n",
            "Epoch 10: val precision@10 = 0.0025\n",
            "Epoch 11: val precision@10 = 0.0030\n",
            "Epoch 12: val precision@10 = 0.0032\n",
            "Epoch 13: val precision@10 = 0.0033\n",
            "Epoch 14: val precision@10 = 0.0038\n",
            "Epoch 15: val precision@10 = 0.0040\n",
            "Epoch 16: val precision@10 = 0.0041\n",
            "Epoch 17: val precision@10 = 0.0043\n",
            "Epoch 18: val precision@10 = 0.0044\n",
            "Epoch 19: val precision@10 = 0.0042\n",
            "Epoch 20: val precision@10 = 0.0044\n",
            "Epoch 21: val precision@10 = 0.0046\n",
            "Epoch 22: val precision@10 = 0.0049\n",
            "Epoch 23: val precision@10 = 0.0052\n",
            "Epoch 24: val precision@10 = 0.0056\n",
            "Epoch 25: val precision@10 = 0.0057\n",
            "Epoch 26: val precision@10 = 0.0061\n",
            "Epoch 27: val precision@10 = 0.0064\n",
            "Epoch 28: val precision@10 = 0.0067\n",
            "Epoch 29: val precision@10 = 0.0067\n",
            "Epoch 30: val precision@10 = 0.0070\n",
            "Validation Precision@10: 0.0070\n",
            "\n",
            "Trying config: {'feat': '001010', 'min_user': 10, 'min_item': 20, 'dim': 16, 'lr': 0.03, 'loss': 'bpr', 'alpha': 1e-05}\n",
            "Sparsity: 0.001059\n",
            "Epoch 1: val precision@10 = 0.0000\n",
            "Epoch 2: val precision@10 = 0.0001\n",
            "Epoch 3: val precision@10 = 0.0002\n",
            "Epoch 4: val precision@10 = 0.0004\n",
            "Epoch 5: val precision@10 = 0.0006\n",
            "Epoch 6: val precision@10 = 0.0007\n",
            "Epoch 7: val precision@10 = 0.0010\n",
            "Epoch 8: val precision@10 = 0.0012\n",
            "Epoch 9: val precision@10 = 0.0019\n",
            "Epoch 10: val precision@10 = 0.0023\n",
            "Epoch 11: val precision@10 = 0.0025\n",
            "Epoch 12: val precision@10 = 0.0026\n",
            "Epoch 13: val precision@10 = 0.0026\n",
            "Epoch 14: val precision@10 = 0.0030\n",
            "Epoch 15: val precision@10 = 0.0032\n",
            "Epoch 16: val precision@10 = 0.0035\n",
            "Epoch 17: val precision@10 = 0.0036\n",
            "Epoch 18: val precision@10 = 0.0041\n",
            "Epoch 19: val precision@10 = 0.0042\n",
            "Epoch 20: val precision@10 = 0.0042\n",
            "Epoch 21: val precision@10 = 0.0043\n",
            "Epoch 22: val precision@10 = 0.0046\n",
            "Epoch 23: val precision@10 = 0.0047\n",
            "Epoch 24: val precision@10 = 0.0050\n",
            "Epoch 25: val precision@10 = 0.0056\n",
            "Epoch 26: val precision@10 = 0.0057\n",
            "Epoch 27: val precision@10 = 0.0059\n",
            "Epoch 28: val precision@10 = 0.0063\n",
            "Epoch 29: val precision@10 = 0.0064\n",
            "Epoch 30: val precision@10 = 0.0070\n",
            "Validation Precision@10: 0.0070\n",
            "\n",
            "Trying config: {'feat': '001010', 'min_user': 10, 'min_item': 20, 'dim': 32, 'lr': 0.01, 'loss': 'warp', 'alpha': 1e-06}\n",
            "Sparsity: 0.001059\n",
            "Epoch 1: val precision@10 = 0.0004\n",
            "Epoch 2: val precision@10 = 0.0016\n",
            "Epoch 3: val precision@10 = 0.0025\n",
            "Epoch 4: val precision@10 = 0.0034\n",
            "Epoch 5: val precision@10 = 0.0041\n",
            "Epoch 6: val precision@10 = 0.0052\n",
            "Epoch 7: val precision@10 = 0.0060\n",
            "Epoch 8: val precision@10 = 0.0067\n",
            "Epoch 9: val precision@10 = 0.0072\n",
            "Epoch 10: val precision@10 = 0.0079\n",
            "Epoch 11: val precision@10 = 0.0084\n",
            "Epoch 12: val precision@10 = 0.0090\n",
            "Epoch 13: val precision@10 = 0.0099\n",
            "Epoch 14: val precision@10 = 0.0104\n",
            "Epoch 15: val precision@10 = 0.0112\n",
            "Epoch 16: val precision@10 = 0.0116\n",
            "Epoch 17: val precision@10 = 0.0118\n",
            "Epoch 18: val precision@10 = 0.0126\n",
            "Epoch 19: val precision@10 = 0.0132\n",
            "Epoch 20: val precision@10 = 0.0136\n",
            "Epoch 21: val precision@10 = 0.0142\n",
            "Epoch 22: val precision@10 = 0.0145\n",
            "Epoch 23: val precision@10 = 0.0148\n",
            "Epoch 24: val precision@10 = 0.0151\n",
            "Epoch 25: val precision@10 = 0.0154\n",
            "Epoch 26: val precision@10 = 0.0155\n",
            "Epoch 27: val precision@10 = 0.0160\n",
            "Epoch 28: val precision@10 = 0.0162\n",
            "Epoch 29: val precision@10 = 0.0166\n",
            "Epoch 30: val precision@10 = 0.0170\n",
            "Validation Precision@10: 0.0170\n",
            "\n",
            "Trying config: {'feat': '001010', 'min_user': 10, 'min_item': 20, 'dim': 32, 'lr': 0.01, 'loss': 'warp', 'alpha': 1e-05}\n",
            "Sparsity: 0.001059\n",
            "Epoch 1: val precision@10 = 0.0008\n",
            "Epoch 2: val precision@10 = 0.0014\n",
            "Epoch 3: val precision@10 = 0.0028\n",
            "Epoch 4: val precision@10 = 0.0034\n",
            "Epoch 5: val precision@10 = 0.0040\n",
            "Epoch 6: val precision@10 = 0.0052\n",
            "Epoch 7: val precision@10 = 0.0061\n",
            "Epoch 8: val precision@10 = 0.0069\n",
            "Epoch 9: val precision@10 = 0.0079\n",
            "Epoch 10: val precision@10 = 0.0083\n",
            "Epoch 11: val precision@10 = 0.0089\n",
            "Epoch 12: val precision@10 = 0.0093\n",
            "Epoch 13: val precision@10 = 0.0099\n",
            "Epoch 14: val precision@10 = 0.0110\n",
            "Epoch 15: val precision@10 = 0.0120\n",
            "Epoch 16: val precision@10 = 0.0123\n",
            "Epoch 17: val precision@10 = 0.0129\n",
            "Epoch 18: val precision@10 = 0.0133\n",
            "Epoch 19: val precision@10 = 0.0138\n",
            "Epoch 20: val precision@10 = 0.0141\n",
            "Epoch 21: val precision@10 = 0.0142\n",
            "Epoch 22: val precision@10 = 0.0146\n",
            "Epoch 23: val precision@10 = 0.0148\n",
            "Epoch 24: val precision@10 = 0.0151\n",
            "Epoch 25: val precision@10 = 0.0151\n",
            "Epoch 26: val precision@10 = 0.0153\n",
            "Epoch 27: val precision@10 = 0.0157\n",
            "Epoch 28: val precision@10 = 0.0161\n",
            "Epoch 29: val precision@10 = 0.0161\n",
            "Epoch 30: val precision@10 = 0.0163\n",
            "Validation Precision@10: 0.0163\n",
            "\n",
            "Trying config: {'feat': '001010', 'min_user': 10, 'min_item': 20, 'dim': 32, 'lr': 0.01, 'loss': 'bpr', 'alpha': 1e-06}\n",
            "Sparsity: 0.001059\n",
            "Epoch 1: val precision@10 = 0.0001\n",
            "Epoch 2: val precision@10 = 0.0002\n",
            "Epoch 3: val precision@10 = 0.0001\n",
            "Epoch 4: val precision@10 = 0.0002\n",
            "Epoch 5: val precision@10 = 0.0002\n",
            "Epoch 6: val precision@10 = 0.0002\n",
            "Early stopping at epoch 6\n",
            "Validation Precision@10: 0.0001\n",
            "\n",
            "Trying config: {'feat': '001010', 'min_user': 10, 'min_item': 20, 'dim': 32, 'lr': 0.01, 'loss': 'bpr', 'alpha': 1e-05}\n",
            "Sparsity: 0.001059\n",
            "Epoch 1: val precision@10 = 0.0001\n",
            "Epoch 2: val precision@10 = 0.0002\n",
            "Epoch 3: val precision@10 = 0.0005\n",
            "Epoch 4: val precision@10 = 0.0005\n",
            "Epoch 5: val precision@10 = 0.0005\n",
            "Epoch 6: val precision@10 = 0.0004\n",
            "Epoch 7: val precision@10 = 0.0006\n",
            "Epoch 8: val precision@10 = 0.0006\n",
            "Early stopping at epoch 8\n",
            "Validation Precision@10: 0.0005\n",
            "\n",
            "Trying config: {'feat': '001010', 'min_user': 10, 'min_item': 20, 'dim': 32, 'lr': 0.03, 'loss': 'warp', 'alpha': 1e-06}\n",
            "Sparsity: 0.001059\n",
            "Epoch 1: val precision@10 = 0.0029\n",
            "Epoch 2: val precision@10 = 0.0064\n",
            "Epoch 3: val precision@10 = 0.0096\n",
            "Epoch 4: val precision@10 = 0.0126\n",
            "Epoch 5: val precision@10 = 0.0150\n",
            "Epoch 6: val precision@10 = 0.0174\n",
            "Epoch 7: val precision@10 = 0.0182\n",
            "Epoch 8: val precision@10 = 0.0194\n",
            "Epoch 9: val precision@10 = 0.0209\n",
            "Epoch 10: val precision@10 = 0.0218\n",
            "Epoch 11: val precision@10 = 0.0228\n",
            "Epoch 12: val precision@10 = 0.0240\n",
            "Epoch 13: val precision@10 = 0.0250\n",
            "Epoch 14: val precision@10 = 0.0254\n",
            "Epoch 15: val precision@10 = 0.0260\n",
            "Epoch 16: val precision@10 = 0.0263\n",
            "Epoch 17: val precision@10 = 0.0268\n",
            "Epoch 18: val precision@10 = 0.0273\n",
            "Epoch 19: val precision@10 = 0.0277\n",
            "Epoch 20: val precision@10 = 0.0281\n",
            "Epoch 21: val precision@10 = 0.0286\n",
            "Epoch 22: val precision@10 = 0.0290\n",
            "Epoch 23: val precision@10 = 0.0298\n",
            "Epoch 24: val precision@10 = 0.0300\n",
            "Epoch 25: val precision@10 = 0.0303\n",
            "Epoch 26: val precision@10 = 0.0305\n",
            "Epoch 27: val precision@10 = 0.0306\n",
            "Epoch 28: val precision@10 = 0.0309\n",
            "Epoch 29: val precision@10 = 0.0313\n",
            "Epoch 30: val precision@10 = 0.0314\n",
            "Validation Precision@10: 0.0314\n",
            "\n",
            "Trying config: {'feat': '001010', 'min_user': 10, 'min_item': 20, 'dim': 32, 'lr': 0.03, 'loss': 'warp', 'alpha': 1e-05}\n",
            "Sparsity: 0.001059\n",
            "Epoch 1: val precision@10 = 0.0027\n",
            "Epoch 2: val precision@10 = 0.0066\n",
            "Epoch 3: val precision@10 = 0.0101\n",
            "Epoch 4: val precision@10 = 0.0128\n",
            "Epoch 5: val precision@10 = 0.0152\n",
            "Epoch 6: val precision@10 = 0.0170\n",
            "Epoch 7: val precision@10 = 0.0181\n",
            "Epoch 8: val precision@10 = 0.0194\n",
            "Epoch 9: val precision@10 = 0.0206\n",
            "Epoch 10: val precision@10 = 0.0218\n",
            "Epoch 11: val precision@10 = 0.0225\n",
            "Epoch 12: val precision@10 = 0.0234\n",
            "Epoch 13: val precision@10 = 0.0241\n",
            "Epoch 14: val precision@10 = 0.0250\n",
            "Epoch 15: val precision@10 = 0.0249\n",
            "Epoch 16: val precision@10 = 0.0256\n",
            "Epoch 17: val precision@10 = 0.0263\n",
            "Epoch 18: val precision@10 = 0.0268\n",
            "Epoch 19: val precision@10 = 0.0272\n",
            "Epoch 20: val precision@10 = 0.0277\n",
            "Epoch 21: val precision@10 = 0.0284\n",
            "Epoch 22: val precision@10 = 0.0288\n",
            "Epoch 23: val precision@10 = 0.0291\n",
            "Epoch 24: val precision@10 = 0.0295\n",
            "Epoch 25: val precision@10 = 0.0297\n",
            "Epoch 26: val precision@10 = 0.0298\n",
            "Epoch 27: val precision@10 = 0.0298\n",
            "Epoch 28: val precision@10 = 0.0303\n",
            "Epoch 29: val precision@10 = 0.0306\n",
            "Epoch 30: val precision@10 = 0.0308\n",
            "Validation Precision@10: 0.0308\n",
            "\n",
            "Trying config: {'feat': '001010', 'min_user': 10, 'min_item': 20, 'dim': 32, 'lr': 0.03, 'loss': 'bpr', 'alpha': 1e-06}\n",
            "Sparsity: 0.001059\n",
            "Epoch 1: val precision@10 = 0.0000\n",
            "Epoch 2: val precision@10 = 0.0002\n",
            "Epoch 3: val precision@10 = 0.0008\n",
            "Epoch 4: val precision@10 = 0.0008\n",
            "Epoch 5: val precision@10 = 0.0009\n",
            "Epoch 6: val precision@10 = 0.0010\n",
            "Epoch 7: val precision@10 = 0.0013\n",
            "Epoch 8: val precision@10 = 0.0012\n",
            "Epoch 9: val precision@10 = 0.0017\n",
            "Epoch 10: val precision@10 = 0.0019\n",
            "Epoch 11: val precision@10 = 0.0024\n",
            "Epoch 12: val precision@10 = 0.0027\n",
            "Epoch 13: val precision@10 = 0.0032\n",
            "Epoch 14: val precision@10 = 0.0034\n",
            "Epoch 15: val precision@10 = 0.0036\n",
            "Epoch 16: val precision@10 = 0.0034\n",
            "Epoch 17: val precision@10 = 0.0035\n",
            "Epoch 18: val precision@10 = 0.0037\n",
            "Epoch 19: val precision@10 = 0.0041\n",
            "Epoch 20: val precision@10 = 0.0043\n",
            "Epoch 21: val precision@10 = 0.0046\n",
            "Epoch 22: val precision@10 = 0.0049\n",
            "Epoch 23: val precision@10 = 0.0054\n",
            "Epoch 24: val precision@10 = 0.0055\n",
            "Epoch 25: val precision@10 = 0.0059\n",
            "Epoch 26: val precision@10 = 0.0063\n",
            "Epoch 27: val precision@10 = 0.0066\n",
            "Epoch 28: val precision@10 = 0.0068\n",
            "Epoch 29: val precision@10 = 0.0071\n",
            "Epoch 30: val precision@10 = 0.0073\n",
            "Validation Precision@10: 0.0073\n",
            "\n",
            "Trying config: {'feat': '001010', 'min_user': 10, 'min_item': 20, 'dim': 32, 'lr': 0.03, 'loss': 'bpr', 'alpha': 1e-05}\n",
            "Sparsity: 0.001059\n",
            "Epoch 1: val precision@10 = 0.0003\n",
            "Epoch 2: val precision@10 = 0.0005\n",
            "Epoch 3: val precision@10 = 0.0007\n",
            "Epoch 4: val precision@10 = 0.0009\n",
            "Epoch 5: val precision@10 = 0.0009\n",
            "Epoch 6: val precision@10 = 0.0012\n",
            "Epoch 7: val precision@10 = 0.0012\n",
            "Epoch 8: val precision@10 = 0.0012\n",
            "Epoch 9: val precision@10 = 0.0014\n",
            "Epoch 10: val precision@10 = 0.0020\n",
            "Epoch 11: val precision@10 = 0.0025\n",
            "Epoch 12: val precision@10 = 0.0027\n",
            "Epoch 13: val precision@10 = 0.0030\n",
            "Epoch 14: val precision@10 = 0.0035\n",
            "Epoch 15: val precision@10 = 0.0035\n",
            "Epoch 16: val precision@10 = 0.0037\n",
            "Epoch 17: val precision@10 = 0.0041\n",
            "Epoch 18: val precision@10 = 0.0045\n",
            "Epoch 19: val precision@10 = 0.0045\n",
            "Epoch 20: val precision@10 = 0.0044\n",
            "Epoch 21: val precision@10 = 0.0046\n",
            "Epoch 22: val precision@10 = 0.0049\n",
            "Epoch 23: val precision@10 = 0.0055\n",
            "Epoch 24: val precision@10 = 0.0056\n",
            "Epoch 25: val precision@10 = 0.0060\n",
            "Epoch 26: val precision@10 = 0.0064\n",
            "Epoch 27: val precision@10 = 0.0065\n",
            "Epoch 28: val precision@10 = 0.0068\n",
            "Epoch 29: val precision@10 = 0.0069\n",
            "Epoch 30: val precision@10 = 0.0071\n",
            "Validation Precision@10: 0.0071\n",
            "\n",
            "===== BEST CONFIG =====\n",
            "{'feat': '001010', 'min_user': 10, 'min_item': 20, 'dim': 32, 'lr': 0.03, 'loss': 'warp', 'alpha': 1e-06}\n",
            "========================\n",
            "\n",
            "Final Evaluation Results:\n",
            "HR@10: 0.0553\n",
            "NDCG@10: 0.0194\n",
            "Precision@10: 0.0077\n",
            "Recall@10: 0.0273\n",
            "MAP: 0.0116\n",
            "AUC: 0.9070\n"
          ]
        }
      ],
      "source": [
        "config_base = {\n",
        "    'feat': '001010',\n",
        "    'min_user': 10,\n",
        "    'min_item': 20\n",
        "}\n",
        "simple_grid_search_and_run(\n",
        "    config_base=config_base,\n",
        "    dim_list=[16, 32],\n",
        "    lr_list=[0.01, 0.03],\n",
        "    loss_list=['warp', 'bpr'],\n",
        "    alpha_list=[1e-6, 1e-5]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "XQvD6_1Jf7V0",
      "metadata": {
        "id": "XQvD6_1Jf7V0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
